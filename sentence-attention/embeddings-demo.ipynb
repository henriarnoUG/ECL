{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a38751",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67ee863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from main and experiments library\n",
    "import os\n",
    "from sentence_lib import *\n",
    "os.chdir(\"../\")\n",
    "from library import *\n",
    "\n",
    "# filter the warnings for clarity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ee1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# specific imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ec589",
   "metadata": {},
   "source": [
    "#### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6336077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and add financial features\n",
    "dataset = pd.read_csv('ECL.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa1c07",
   "metadata": {},
   "source": [
    "#### Functions to embedd documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3ba012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encode sentences\n",
    "\n",
    "def doc_encode(text_path, sentence_encoder):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text_path (str): path to text document to encode (.txt)\n",
    "        sentence_encoder (sentence_transformer model): model from sentence_transformer library to encode sentences\n",
    "    Returns:\n",
    "        Array with dense vector representations of the sentences in the document with shape (n_sentences, embedding_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    # read text file\n",
    "    with open(text_path, 'r', encoding=\"utf8\") as file:\n",
    "        text = file.read().strip()\n",
    "\n",
    "    # handle empty documents\n",
    "    if (text is None) or (text == ''):\n",
    "        text = \"not included\"\n",
    "\n",
    "    # tokenize document into sentences and encode\n",
    "    sentences = sent_tokenize(text)\n",
    "    embeddings = sentence_encoder.encode(sentences, batch_size=32)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e44fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to padd embeddings and masks\n",
    "\n",
    "def pad_embeddings(embeddings, max_sentences):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        embeddings (np Array): Array with dense vector representations of the sentences in the document \n",
    "            with shape (n_sentences, embedding_dim).\n",
    "        max_sentences (int): Maximum number of sentences that are encoded. If the document contains more sentences than \n",
    "            `max_sentences`, the embeddings are truncated to the first `max_sentences/2` and last `max_sentences/2` sentences. \n",
    "            If fewer sentences are present, the embeddings are padded with zero rows to reach `max_sentences` rows.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            - padded_embeddings (np Array): Array of shape (max_sentences, embedding_dim) containing the first `max_sentences/2`\n",
    "              and last `max_sentences/2` sentence embeddings if the document has more than `max_sentences` sentences. Otherwise, \n",
    "              the array contains all sentence embeddings from the document, padded with zero rows if necessary.\n",
    "            - padding_mask (np Array): Array of shape (max_sentences,) where 0 indicates a row that contains an original sentence \n",
    "              embedding and 1 indicates a row that was added as padding.\n",
    "    \"\"\"\n",
    "    # get dimensions\n",
    "    n_sentences, embedding_dim = embeddings.shape\n",
    "\n",
    "    # long documents\n",
    "    if n_sentences > max_sentences:\n",
    "\n",
    "        # padded embeddings\n",
    "        half = max_sentences // 2\n",
    "        first_part = embeddings[:half]\n",
    "        last_part = embeddings[-half:]\n",
    "        padded_embeddings = np.vstack((first_part, last_part))\n",
    "\n",
    "        # padding mask\n",
    "        padding_mask = np.zeros(max_sentences)\n",
    "    \n",
    "    # short documents\n",
    "    else:\n",
    "\n",
    "        # padded embeddings\n",
    "        padded_embeddings = np.zeros((max_sentences, embedding_dim))\n",
    "        padded_embeddings[:n_sentences] = embeddings\n",
    "\n",
    "        # padding mask\n",
    "        padding_mask = np.zeros(max_sentences)\n",
    "        padding_mask[n_sentences:] = 1\n",
    "    \n",
    "    return padded_embeddings, padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4437f0",
   "metadata": {},
   "source": [
    "#### show functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a40ac",
   "metadata": {},
   "source": [
    "In this notebook, we show how to encode a single document. In the experiments, we encoded each document and stored the embeddings and masks on disk in the './data/embeddings/' and './data/masks/' folders. When storing in a different location, adjust the SentenceDataset class in the sentence_lib accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bea999",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# init encoder\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentence_encoder = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39da20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try code\n",
    "text_path = './data/' + dataset.iloc[100]['filename']\n",
    "embeddings = doc_encode(text_path, sentence_encoder)\n",
    "padded, mask = pad_embeddings(embeddings, max_sentences=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a110da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 384)\n"
     ]
    }
   ],
   "source": [
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db807f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b04d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.055616    0.05003147 -0.01406426 ... -0.0037985   0.03559393\n",
      "   0.06389399]\n",
      " [-0.0291768  -0.01175649 -0.009448   ... -0.0744302   0.0024586\n",
      "  -0.03813057]\n",
      " [ 0.04579611 -0.04939097 -0.00142446 ... -0.05362279  0.0131751\n",
      "  -0.00074564]\n",
      " ...\n",
      " [-0.12523738  0.11033276  0.017206   ... -0.03009926  0.0052035\n",
      "  -0.05920722]\n",
      " [-0.09224969  0.01656992  0.0325099  ...  0.00809553 -0.02889522\n",
      "   0.00556058]\n",
      " [-0.03287739 -0.05005996 -0.02797735 ... -0.08235028  0.06761632\n",
      "   0.00291118]]\n"
     ]
    }
   ],
   "source": [
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95fe591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e968d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
