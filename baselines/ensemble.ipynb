{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8a5496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from main and experiments library\n",
    "import os\n",
    "from experiments_lib import *\n",
    "os.chdir(\"../\")\n",
    "from library import *\n",
    "\n",
    "# filter the warnings for clarity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc37ba",
   "metadata": {},
   "source": [
    "#### business failure prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72dbaba",
   "metadata": {},
   "source": [
    "We use the ECL benchmark dataset to predict next-year business failure from the multi-modal data contained in corporate 10K records. To this end, we use the following variables:\n",
    "\n",
    "- ```qualified```: \"Yes\" if the 10K record qualifies for inclusion in the LoPucki BRD, \"No\" if the 10K record does not qualify for inclusion in the LoPucki BRD and \"out-of-period\" if the 10K records was filed before 1993 or after 2021.\n",
    "- ```can_label```: \"True\" if we have all the necessary information to assign a label to the 10K record (```filing date``` and ```total asset value```), \"False\" otherwise\n",
    "- ```label```: \"True\" if the company filed for bankruptcy in the year following the filing date of the 10K, \"False\" otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d6a7b",
   "metadata": {},
   "source": [
    "#### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9acd75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 115373 rows from CompuStat based on screening variables\n",
      "0 records in the dataset do not have an accompanying CompuStat record.\n"
     ]
    }
   ],
   "source": [
    "# specify path\n",
    "path_ECL = '../bankruptcy research data/ECL.csv' # change path to correct location\n",
    "path_CS = '../bankruptcy research data/Compustat/data.csv' # change path to correct location\n",
    "\n",
    "# read data and add financial features\n",
    "dataset = pd.read_csv(path_ECL, index_col=0)\n",
    "dataset = compustat_local(path_CS, dataset, update=False)\n",
    "dataset, predictors = compute_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59223165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train val test set\n",
    "subset = dataset.loc[(dataset['can_label'] == True) & (dataset['qualified'] == 'Yes')].reset_index(drop=True)\n",
    "subset['fyear'] = pd.to_datetime(subset['filing_date']).dt.year\n",
    "\n",
    "\n",
    "train = subset.loc[subset['bankruptcy_prediction_split'] == 'train']\n",
    "test = subset.loc[subset['bankruptcy_prediction_split'] == 'test']\n",
    "val = train.loc[train['fyear'] > 2011]\n",
    "train_small = train.drop(val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95fcac",
   "metadata": {},
   "source": [
    "#### XGBoost baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b774a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store predictors and labels\n",
    "small_X = train_small[predictors]\n",
    "small_y = train_small['label']\n",
    "\n",
    "val_X = val[predictors]\n",
    "val_y = val['label']\n",
    "\n",
    "train_X = train[predictors]\n",
    "train_y = train['label']\n",
    "\n",
    "test_X = test[predictors]\n",
    "test_y = test['label']\n",
    "\n",
    "# resample training data\n",
    "ros = RandomOverSampler(random_state=0, sampling_strategy=1)\n",
    "small_X, small_y = ros.fit_resample(small_X, small_y)\n",
    "train_X, train_y = ros.fit_resample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d238808d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the pipelines\n",
    "XGB_small = Pipeline([ ('scaler', StandardScaler()), \n",
    "                      ('clf', xgb.XGBClassifier(objective='binary:logistic', subsample=0.5, eta=0.1, \n",
    "                                                max_depth = 1, n_estimators = 1000))])\n",
    "\n",
    "XGB_train = Pipeline([ ('scaler', StandardScaler()), \n",
    "                      ('clf', xgb.XGBClassifier(objective='binary:logistic', subsample=0.5, eta=0.1, \n",
    "                                                max_depth = 1, n_estimators = 1000))])\n",
    "\n",
    "# train model\n",
    "XGB_small.fit(X=small_X, y=small_y)\n",
    "XGB_train.fit(X=train_X, y=train_y)\n",
    "\n",
    "# evaluate the model\n",
    "val_preds = XGB_small.predict_proba(val_X)[:, 1]\n",
    "test_preds = XGB_train.predict_proba(test_X)[:, 1]\n",
    "val[\"preds_XGB\"] = val_preds\n",
    "test[\"preds_XGB\"] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ffd8e",
   "metadata": {},
   "source": [
    "#### TF-IDF baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c81f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split predictors and labels\n",
    "small_X = clean_corpus + train_small['filename']\n",
    "small_y = train_small['label']\n",
    "\n",
    "val_X = clean_corpus + val['filename']\n",
    "val_y = val['label']\n",
    "\n",
    "train_X = clean_corpus + train['filename']\n",
    "train_y = train['label']\n",
    "\n",
    "test_X = clean_corpus + test['filename']\n",
    "test_y = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef17d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline\n",
    "TF_IDF_small = Pipeline([\n",
    "    ('vect', TfidfVectorizer(input='filename', lowercase=True, \n",
    "                                 strip_accents='ascii', stop_words='english', min_df=2, ngram_range = (1,2))),\n",
    "    ('clf', LogisticRegression(penalty = 'l1', C = 1, class_weight = 'balanced', \n",
    "                                   solver='liblinear'))])\n",
    "\n",
    "TF_IDF_train = Pipeline([\n",
    "    ('vect', TfidfVectorizer(input='filename', lowercase=True, \n",
    "                                 strip_accents='ascii', stop_words='english', min_df=2, ngram_range = (1,2))),\n",
    "    ('clf', LogisticRegression(penalty = 'l1', C = 1, class_weight = 'balanced', \n",
    "                                   solver='liblinear'))])\n",
    "\n",
    "# train model\n",
    "TF_IDF_small.fit(X=small_X, y= small_y)\n",
    "TF_IDF_train.fit(X=train_X, y= train_y)\n",
    "\n",
    "# evaluate the model\n",
    "val_preds = TF_IDF_small.predict_proba(val_X)[:, 1]\n",
    "test_preds = TF_IDF_train.predict_proba(test_X)[:, 1]\n",
    "val[\"preds_TFIDF\"] = val_preds\n",
    "test[\"preds_TFIDF\"] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f15749",
   "metadata": {},
   "source": [
    "#### stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f25a193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split predictors and labels\n",
    "train_X = val[[\"preds_XGB\", \"preds_TFIDF\"]]\n",
    "train_y = val['label']\n",
    "\n",
    "test_X = test[[\"preds_XGB\", \"preds_TFIDF\"]]\n",
    "test_y = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c6ce53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RESULTS --\n",
      "AUC: 0.9479\n",
      "AP: 0.2639\n",
      "recall@100: 0.2869\n",
      "CAP: 0.8958\n"
     ]
    }
   ],
   "source": [
    "# create the pipelines\n",
    "stacking_clf = Pipeline([('scaler', StandardScaler()),\n",
    "                         ('clf', LogisticRegression(penalty='l2', C =1 , class_weight='balanced'))])\n",
    "\n",
    "# train\n",
    "stacking_clf.fit(X=train_X, y = train_y)\n",
    "\n",
    "# evaluate the model\n",
    "preds = stacking_clf.predict_proba(test_X)[:, 1]\n",
    "evaluate(labels=test_y, predictions=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731a2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
